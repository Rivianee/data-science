{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOYM4Qr+qyWzoyd9C/IcbEb"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Implementação em Python para Comparação de Modelos"
      ],
      "metadata": {
        "id": "FRCu36878Txt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Objetivo: implementar as fórmulas de RER (Taxa de Erro Reduzida) e IAR (Taxa de Precisão Aumentada) em código para ambos os casos: regressão e classificação.\n",
        "\n",
        "# Para isso, vamos considerar que temos modelos para ambos os casos e que cada modelo possui métricas específicas que queremos comparar."
      ],
      "metadata": {
        "id": "9bI1A31_9iQq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Escolha dos Indicadores de Desempenho:\n",
        "\n",
        "Identifique os indicadores de desempenho que deseja comparar entre dois modelos. Por exemplo, RMSE para erro e R² para ajuste.\n",
        "Definição dos Modelos:\n",
        "\n",
        "Para cada modelo, determine os valores dos indicadores de desempenho que você escolheu. Por exemplo:\n",
        "Modelo A: RMSE = 10, R² = 0.85\n",
        "Modelo B: RMSE = 8, R² = 0.90"
      ],
      "metadata": {
        "id": "BiXYYq8k-f92"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### REGRESSÃO"
      ],
      "metadata": {
        "id": "sdJ-nTT98WqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calcular_RER_regressao(indicador_base, indicador_comparacao):\n",
        "    \"\"\"Calcula a taxa de erro reduzida (RER) para métricas de regressão.\"\"\"\n",
        "    try:\n",
        "        return (indicador_base - indicador_comparacao) / indicador_base\n",
        "    except ZeroDivisionError:\n",
        "        raise ValueError(\"O indicador base não pode ser zero.\")\n",
        "\n",
        "def calcular_IAR_regressao(indicador_base, indicador_comparacao):\n",
        "    \"\"\"Calcula a taxa de precisão aumentada (IAR) para métricas de regressão.\"\"\"\n",
        "    try:\n",
        "        return (indicador_comparacao - indicador_base) / indicador_base\n",
        "    except ZeroDivisionError:\n",
        "        raise ValueError(\"O indicador base não pode ser zero.\")\n",
        "\n",
        "def comparar_modelos_regressao(modelo_base, modelo_comparacao):\n",
        "    \"\"\"Realiza a comparação entre modelos de regressão.\"\"\"\n",
        "    indicador_base_RMSE = modelo_base.get('RMSE', 0.0)\n",
        "    indicador_comparacao_RMSE = modelo_comparacao.get('RMSE', 0.0)\n",
        "    indicador_base_R2 = modelo_base.get('R2', 0.0)\n",
        "    indicador_comparacao_R2 = modelo_comparacao.get('R2', 0.0)\n",
        "\n",
        "    RER_RMSE = calcular_RER_regressao(indicador_base_RMSE, indicador_comparacao_RMSE)\n",
        "    IAR_RMSE = calcular_IAR_regressao(indicador_base_RMSE, indicador_comparacao_RMSE)\n",
        "    RER_R2 = calcular_RER_regressao(indicador_base_R2, indicador_comparacao_R2)\n",
        "    IAR_R2 = calcular_IAR_regressao(indicador_base_R2, indicador_comparacao_R2)\n",
        "\n",
        "    return RER_RMSE, IAR_RMSE, RER_R2, IAR_R2\n",
        "\n",
        "# Exemplo fictício de dados de desempenho para regressão\n",
        "modelo_base_regressao = {\n",
        "    'RMSE': 10.0,\n",
        "    'R2': 0.85,\n",
        "}\n",
        "\n",
        "modelo_comparacao_regressao = {\n",
        "    'RMSE': 8.0,\n",
        "    'R2': 0.90,\n",
        "}\n",
        "\n",
        "# Realizar comparação entre modelos de regressão e exibir resultados\n",
        "RER_RMSE, IAR_RMSE, RER_R2, IAR_R2 = comparar_modelos_regressao(modelo_base_regressao, modelo_comparacao_regressao)\n",
        "\n",
        "print(\"Comparação entre modelos de regressão:\")\n",
        "print(f\"  Taxa de erro reduzida (RER) para RMSE: {RER_RMSE:.2f}\")\n",
        "print(f\"  Taxa de precisão aumentada (IAR) para RMSE: {IAR_RMSE:.2f}\")\n",
        "print(f\"  Taxa de erro reduzida (RER) para R²: {RER_R2:.2f}\")\n",
        "print(f\"  Taxa de precisão aumentada (IAR) para R²: {IAR_R2:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8Axu3GKA2un",
        "outputId": "15291b52-3fbd-44a2-ea77-0fab0157a380"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comparação entre modelos de regressão:\n",
            "  Taxa de erro reduzida (RER) para RMSE: 0.20\n",
            "  Taxa de precisão aumentada (IAR) para RMSE: -0.20\n",
            "  Taxa de erro reduzida (RER) para R²: -0.06\n",
            "  Taxa de precisão aumentada (IAR) para R²: 0.06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Para Regressão\n",
        "\n",
        "# RMSE:\n",
        "\n",
        "RER para RMSE: 0.20 significa que o modelo de comparação tem um RMSE 20% menor que o modelo base.\n",
        "\n",
        "IAR para RMSE: -0.20 significa que o modelo de comparação tem um RMSE 20% maior que o modelo base.\n",
        "R²:\n",
        "\n",
        "# R²\n",
        "\n",
        "RER para R²: -0.06 significa que o modelo de comparação tem um R² 6% menor que o modelo base.\n",
        "\n",
        "IAR para R²: 0.06 significa que o modelo de comparação tem um R² 6% maior que o modelo base.\n",
        "\n",
        "Esses resultados indicam como os modelos de comparação se comportam em relação ao modelo base em termos de precisão (R²) e erro (RMSE). O RER positivo indica melhoria no desempenho do modelo de comparação, enquanto um valor negativo indica piora. O contrário é verdadeiro para o IAR."
      ],
      "metadata": {
        "id": "fav3JX458jNn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CLASSIFICAÇÃO"
      ],
      "metadata": {
        "id": "0rXaufI183B6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "DjghAbQC8-Bk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calcular_RER_classificacao(acuracia_base, acuracia_comparacao):\n",
        "    \"\"\"Calcula a taxa de erro reduzida (RER) para métricas de classificação (acurácia).\"\"\"\n",
        "    try:\n",
        "        return (acuracia_base - acuracia_comparacao) / acuracia_base\n",
        "    except ZeroDivisionError:\n",
        "        raise ValueError(\"A acurácia base não pode ser zero.\")\n",
        "\n",
        "def calcular_IAR_classificacao(acuracia_base, acuracia_comparacao):\n",
        "    \"\"\"Calcula a taxa de precisão aumentada (IAR) para métricas de classificação (acurácia).\"\"\"\n",
        "    try:\n",
        "        return (acuracia_comparacao - acuracia_base) / acuracia_base\n",
        "    except ZeroDivisionError:\n",
        "        raise ValueError(\"A acurácia base não pode ser zero.\")\n",
        "\n",
        "def comparar_modelos_classificacao(modelo_base, modelo_comparacao):\n",
        "    \"\"\"Realiza a comparação entre modelos de classificação.\"\"\"\n",
        "    acuracia_base = modelo_base.get('acuracia', 0.0)\n",
        "    acuracia_comparacao = modelo_comparacao.get('acuracia', 0.0)\n",
        "\n",
        "    RER_acuracia = calcular_RER_classificacao(acuracia_base, acuracia_comparacao)\n",
        "    IAR_acuracia = calcular_IAR_classificacao(acuracia_base, acuracia_comparacao)\n",
        "\n",
        "    return RER_acuracia, IAR_acuracia\n",
        "\n",
        "# Exemplo fictício de dados de desempenho para classificação\n",
        "modelo_base_classificacao = {\n",
        "    'acuracia': 0.85,\n",
        "}\n",
        "\n",
        "modelo_comparacao_classificacao = {\n",
        "    'acuracia': 0.92,\n",
        "}\n",
        "\n",
        "# Realizar comparação entre modelos de classificação e exibir resultados\n",
        "RER_acuracia, IAR_acuracia = comparar_modelos_classificacao(modelo_base_classificacao, modelo_comparacao_classificacao)\n",
        "\n",
        "print(\"Comparação entre modelos de classificação:\")\n",
        "print(f\"  Taxa de erro reduzida (RER) para acurácia: {RER_acuracia:.2f}\")\n",
        "print(f\"  Taxa de precisão aumentada (IAR) para acurácia: {IAR_acuracia:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CrrwU6zc4akQ",
        "outputId": "0f3f8292-9e9d-4c56-f0f4-c03bfe749fb7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comparação entre modelos de classificação:\n",
            "  Taxa de erro reduzida (RER) para acurácia: -0.08\n",
            "  Taxa de precisão aumentada (IAR) para acurácia: 0.08\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Para Classificação:\n",
        "\n",
        "#Acurácia:\n",
        "\n",
        "RER para acurácia: -0.08 significa que o modelo de comparação tem uma acurácia 8% menor que o modelo base.\n",
        "\n",
        "IAR para acurácia: 0.08 significa que o modelo de comparação tem uma acurácia 8% maior que o modelo base.\n",
        "\n",
        "\n",
        "Esses resultados indicam como os modelos de comparação se comportam em relação ao modelo base em termos de acurácia. O RER negativo indica uma piora no desempenho do modelo de comparação em comparação com o modelo base, enquanto um valor positivo de IAR indica uma melhoria."
      ],
      "metadata": {
        "id": "fDkQIgkE9S4c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ATENÇÃO:\n",
        "\n",
        "Certifique-se de adaptar esses exemplos com os indicadores de desempenho específicos que você está utilizando em seus próprios projetos. Essas funções permitem uma comparação direta e objetiva entre modelos usando diferentes métricas de desempenho, facilitando a interpretação dos resultados."
      ],
      "metadata": {
        "id": "5T7SoYgn99aG"
      }
    }
  ]
}