{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMiXGcGFVLAdAK4M9513Jsc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rivianee/data-science/blob/master/COMPARATIVO_MODELOS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementação em Python para Comparação de Modelos"
      ],
      "metadata": {
        "id": "FRCu36878Txt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Objetivo: implementar as fórmulas de RER (Taxa de Erro Reduzida) e IAR (Taxa de Precisão Aumentada) em código para ambos os casos: regressão e classificação.\n",
        "\n",
        "# Para isso, vamos considerar que temos modelos para ambos os casos e que cada modelo possui métricas específicas que queremos comparar."
      ],
      "metadata": {
        "id": "9bI1A31_9iQq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Escolha dos Indicadores de Desempenho:\n",
        "\n",
        "Identifique os indicadores de desempenho que deseja comparar entre dois modelos. Por exemplo, RMSE para erro e R² para ajuste.\n",
        "Definição dos Modelos:\n",
        "\n",
        "Para cada modelo, determine os valores dos indicadores de desempenho que você escolheu. Por exemplo:\n",
        "Modelo A: RMSE = 10, R² = 0.85\n",
        "Modelo B: RMSE = 8, R² = 0.90"
      ],
      "metadata": {
        "id": "BiXYYq8k-f92"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### REGRESSÃO"
      ],
      "metadata": {
        "id": "sdJ-nTT98WqM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oaCMOdu83ypI",
        "outputId": "441b61ee-1d20-494d-84d0-8ab084717158"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comparação entre modelos de regressão:\n",
            "  Taxa de erro reduzida (RER) para RMSE: 0.20\n",
            "  Taxa de precisão aumentada (IAR) para RMSE: -0.20\n",
            "  Taxa de erro reduzida (RER) para R²: -0.06\n",
            "  Taxa de precisão aumentada (IAR) para R²: 0.06\n"
          ]
        }
      ],
      "source": [
        "# Função para calcular taxa de erro reduzida (RER) para métrica de regressão (ex: RMSE)\n",
        "def calcular_RER_regressao(indicador_base, indicador_comparacao):\n",
        "    return (indicador_base - indicador_comparacao) / indicador_base\n",
        "\n",
        "# Função para calcular taxa de precisão aumentada (IAR) para métrica de regressão (ex: R²)\n",
        "def calcular_IAR_regressao(indicador_base, indicador_comparacao):\n",
        "    return (indicador_comparacao - indicador_base) / indicador_base\n",
        "\n",
        "# Função para realizar comparação entre modelos de regressão\n",
        "def comparar_modelos_regressao(modelo_base, modelo_comparacao):\n",
        "    # Extraindo os indicadores de desempenho dos modelos\n",
        "    indicador_base_RMSE = modelo_base['RMSE']\n",
        "    indicador_comparacao_RMSE = modelo_comparacao['RMSE']\n",
        "    indicador_base_R2 = modelo_base['R2']\n",
        "    indicador_comparacao_R2 = modelo_comparacao['R2']\n",
        "\n",
        "    # Calculando RER e IAR para RMSE\n",
        "    RER_RMSE = calcular_RER_regressao(indicador_base_RMSE, indicador_comparacao_RMSE)\n",
        "    IAR_RMSE = calcular_IAR_regressao(indicador_base_RMSE, indicador_comparacao_RMSE)\n",
        "\n",
        "    # Calculando RER e IAR para R²\n",
        "    RER_R2 = calcular_RER_regressao(indicador_base_R2, indicador_comparacao_R2)\n",
        "    IAR_R2 = calcular_IAR_regressao(indicador_base_R2, indicador_comparacao_R2)\n",
        "\n",
        "    return RER_RMSE, IAR_RMSE, RER_R2, IAR_R2\n",
        "\n",
        "# Exemplo fictício de dados de desempenho para regressão\n",
        "modelo_base_regressao = {\n",
        "    'RMSE': 10.0,  # Exemplo de RMSE do modelo base\n",
        "    'R2': 0.85,    # Exemplo de R² do modelo base\n",
        "}\n",
        "\n",
        "modelo_comparacao_regressao = {\n",
        "    'RMSE': 8.0,   # Exemplo de RMSE do modelo de comparação\n",
        "    'R2': 0.90,    # Exemplo de R² do modelo de comparação\n",
        "}\n",
        "\n",
        "# Realizar comparação entre modelos de regressão e exibir resultados\n",
        "RER_RMSE, IAR_RMSE, RER_R2, IAR_R2 = comparar_modelos_regressao(modelo_base_regressao, modelo_comparacao_regressao)\n",
        "\n",
        "print(\"Comparação entre modelos de regressão:\")\n",
        "print(f\"  Taxa de erro reduzida (RER) para RMSE: {RER_RMSE:.2f}\")\n",
        "print(f\"  Taxa de precisão aumentada (IAR) para RMSE: {IAR_RMSE:.2f}\")\n",
        "print(f\"  Taxa de erro reduzida (RER) para R²: {RER_R2:.2f}\")\n",
        "print(f\"  Taxa de precisão aumentada (IAR) para R²: {IAR_R2:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Para Regressão\n",
        "\n",
        "# RMSE:\n",
        "\n",
        "RER para RMSE: 0.20 significa que o modelo de comparação tem um RMSE 20% menor que o modelo base.\n",
        "\n",
        "IAR para RMSE: -0.20 significa que o modelo de comparação tem um RMSE 20% maior que o modelo base.\n",
        "R²:\n",
        "\n",
        "# R²\n",
        "\n",
        "RER para R²: -0.06 significa que o modelo de comparação tem um R² 6% menor que o modelo base.\n",
        "\n",
        "IAR para R²: 0.06 significa que o modelo de comparação tem um R² 6% maior que o modelo base.\n",
        "\n",
        "Esses resultados indicam como os modelos de comparação se comportam em relação ao modelo base em termos de precisão (R²) e erro (RMSE). O RER positivo indica melhoria no desempenho do modelo de comparação, enquanto um valor negativo indica piora. O contrário é verdadeiro para o IAR."
      ],
      "metadata": {
        "id": "fav3JX458jNn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CLASSIFICAÇÃO"
      ],
      "metadata": {
        "id": "0rXaufI183B6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "DjghAbQC8-Bk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Função para calcular taxa de erro reduzida (RER) para métrica de classificação (ex: acurácia)\n",
        "def calcular_RER_classificacao(acuracia_base, acuracia_comparacao):\n",
        "    return (acuracia_base - acuracia_comparacao) / acuracia_base\n",
        "\n",
        "# Função para calcular taxa de precisão aumentada (IAR) para métrica de classificação (ex: acurácia)\n",
        "def calcular_IAR_classificacao(acuracia_base, acuracia_comparacao):\n",
        "    return (acuracia_comparacao - acuracia_base) / acuracia_base\n",
        "\n",
        "# Função para realizar comparação entre modelos de classificação\n",
        "def comparar_modelos_classificacao(modelo_base, modelo_comparacao):\n",
        "    # Extraindo as métricas de desempenho dos modelos\n",
        "    acuracia_base = modelo_base['acuracia']\n",
        "    acuracia_comparacao = modelo_comparacao['acuracia']\n",
        "\n",
        "    # Calculando RER e IAR para acurácia\n",
        "    RER_acuracia = calcular_RER_classificacao(acuracia_base, acuracia_comparacao)\n",
        "    IAR_acuracia = calcular_IAR_classificacao(acuracia_base, acuracia_comparacao)\n",
        "\n",
        "    return RER_acuracia, IAR_acuracia\n",
        "\n",
        "# Exemplo fictício de dados de desempenho para classificação\n",
        "modelo_base_classificacao = {\n",
        "    'acuracia': 0.85,  # Acurácia do modelo base para classificação\n",
        "}\n",
        "\n",
        "modelo_comparacao_classificacao = {\n",
        "    'acuracia': 0.92,  # Acurácia do modelo de comparação para classificação\n",
        "}\n",
        "\n",
        "# Realizar comparação entre modelos de classificação e exibir resultados\n",
        "RER_acuracia, IAR_acuracia = comparar_modelos_classificacao(modelo_base_classificacao, modelo_comparacao_classificacao)\n",
        "\n",
        "print(\"Comparação entre modelos de classificação:\")\n",
        "print(f\"  Taxa de erro reduzida (RER) para acurácia: {RER_acuracia:.2f}\")\n",
        "print(f\"  Taxa de precisão aumentada (IAR) para acurácia: {IAR_acuracia:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CrrwU6zc4akQ",
        "outputId": "13bb7519-f45e-46a5-df1e-0d3c8d1d406d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comparação entre modelos de classificação:\n",
            "  Taxa de erro reduzida (RER) para acurácia: -0.08\n",
            "  Taxa de precisão aumentada (IAR) para acurácia: 0.08\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Para Classificação:\n",
        "\n",
        "#Acurácia:\n",
        "\n",
        "RER para acurácia: -0.08 significa que o modelo de comparação tem uma acurácia 8% menor que o modelo base.\n",
        "\n",
        "IAR para acurácia: 0.08 significa que o modelo de comparação tem uma acurácia 8% maior que o modelo base.\n",
        "\n",
        "\n",
        "Esses resultados indicam como os modelos de comparação se comportam em relação ao modelo base em termos de acurácia. O RER negativo indica uma piora no desempenho do modelo de comparação em comparação com o modelo base, enquanto um valor positivo de IAR indica uma melhoria."
      ],
      "metadata": {
        "id": "fDkQIgkE9S4c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ATENÇÃO:\n",
        "\n",
        "Certifique-se de adaptar esses exemplos com os indicadores de desempenho específicos que você está utilizando em seus próprios projetos. Essas funções permitem uma comparação direta e objetiva entre modelos usando diferentes métricas de desempenho, facilitando a interpretação dos resultados."
      ],
      "metadata": {
        "id": "5T7SoYgn99aG"
      }
    }
  ]
}